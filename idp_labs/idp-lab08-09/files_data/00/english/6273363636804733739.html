<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://venturebeat.com/2019/11/17/wayve-raises-20-million-to-give-autonomous-cars-better-ai-brains/"/>
    <meta property="og:site_name" content="VentureBeat"/>
    <meta property="article:published_time" content="2019-11-18T00:02:47+00:00"/>
    <meta property="og:title" content="Wayve raises $20 million to give autonomous cars better AI brains"/>
    <meta property="og:description" content="Wayve, a U.K. startup that's developing AI that teaches cars to drive using reinforced learning, has raised $20 million in a series A round of funding."/>
  </head>
  <body>
    <article>
      <h1>Wayve raises $20 million to give autonomous cars better AI brains</h1>
      <address><time datetime="2019-11-18T00:02:47+00:00">18 Nov 2019, 00:02</time> by <a rel="author" href="https://venturebeat.com/author/paul-sawers/" target="_blank">Paul Sawers</a></address>
      <p><a href="https://wayve.ai/">Wayve</a>, a U.K.-based startup that’s developing artificial intelligence (AI) that teaches cars to drive autonomously using reinforcement learning, simulation, and computer vision, has raised $20 million in a series A round of funding led by Palo Alto venture capital (VC) firm Eclipse Ventures, with participation from Balderton Capital, Compound Ventures, Fly Ventures, and First Minute Capital.</p>
      <p>Several notable angel investors also participated in the round, including <a href="https://venturebeat.com/2017/03/15/uber-appoints-zoubin-ghahramani-as-chief-scientist-3-months-after-acquiring-his-startup-geometric-intelligence/">Uber’s chief scientist</a> Zoubin Ghahramani and Pieter Abbeel, a UC Berkeley robotics professor and pioneer of <a href="https://en.wikipedia.org/wiki/Deep_reinforcement_learning">deep reinforcement learning</a>.</p>
      <p>Founded out of Cambridge, U.K., in 2017, Wayve’s core premise is that the big breakthrough in self-driving cars will come from better AI brains rather than more sensors or “hand-coded” rules. The company said that it trains its autonomous driving system using simulated environments and then transfers that knowledge into the real world, where it emulates how humans adapt to conditions in real time. Wayve’s systems learn from each safety driver intervention to understand why the driver had to intervene, bypassing HD maps, lidar, and other sensors that have become synonymous with the burgeoning autonomous vehicle movement.</p>
      <p>It is worth noting here that Wayve’s machine learning algorithms can work in tandem with any hardware or sensors if that is how an automaker wants to use them, but Wayve’s central pitch is that autonomous cars should be able to learn new environments just like humans do.</p>
      <p>“Our algorithms are learning to become super-human drivers,” Wayve cofounder and CTO Alex Kendall told VentureBeat. “We learn from attentive human driving, which already eliminates the 98.3% of human road errors due to inattention / ineffective driving. We then further improve beyond what humans are capable of with reinforcement learning, by providing feedback to our system.”</p>
      <figure>
        <img src="https://venturebeat.com/wp-content/uploads/2019/11/wayve_ipace_london_3.jpg?resize=1024%2C577&amp;strip=all"/>
        <figcaption>Above: Wayve working with a Jaguar I-Pace</figcaption>
      </figure>
      <h3>Machine learning</h3>
      <p>Wayve insists it can build a safe and effective self-driving vehicle system using end-to-end machine learning, basic cameras, and GPS navigation.</p>
      <p>“As computational powerand data continue to grow, learning-based approaches will become more inevitable, especially for mobile robotics,” Wayve cofounder and CEO Amar Shah said. “The human brain has evolved over millions of years, computers have only had a few decades, but are catching up quickly.”</p>
      <p>Back in April, Wayve <a href="https://wayve.ai/blog/driving-like-human">claimed</a> a “world first” when it demonstrated its technology being used in a vehicle using cameras and satellite navigation (SatNav) in “never-seen-before complex urban environments.” So essentially, the car was just using its machine-powered eyes and brain in real time, rather than leaning on high-definition maps or sophisticated lidar sensors.</p>
      <figure>
        <video src="https://venturebeat.com/wp-content/uploads/2019/11/traffic-1.gif?resize=500%2C281&amp;strip=all" autoplay="" loop=""/>
        <figcaption>Above: Wayve demonstrating a car navigating a narrow U.K. street and giving way to a passing car at a T-junction.</figcaption>
      </figure>
      <p>While it’s true that Wayve’s system appears to be a more elegant and less expensive self-driving technology solution, isn’t there a good reason why companies such as Alphabet’s Waymo are investing significant sums in <a href="https://venturebeat.com/2019/03/06/waymo-is-selling-lidar-sensors-for-robotics-security-and-agriculture/">developing lidar sensors</a>, while the likes of TomTom <a href="https://venturebeat.com/2019/09/05/tomtom-launches-a-fully-autonomous-test-car-to-develop-hd-maps/">are plowing millions into high-quality maps</a>?</p>
      <p>Indeed, for autonomous cars and trucks to traverse busy thoroughfares at high speeds, they must be able to identify and understand their environment to avoid collisions — lidar sensors are designed to measure the distance between the vehicle and environmental objects by illuminating them with laser light and measuring the reflected pulses. But lidar is not perfectly suited for all conditions, which is why HD maps could play a major complementary role in the evolution of autonomous vehicles; they help provide a more accurate representation of the surrounding environment, including lanes, geometry, and traffic signs. They also effectively let cars see around corners, something that lidar or computer vision can’t yet achieve.</p>
      <p>So instinctively, basic SatNav and cameras should mean a less capable vehicle. Even if the system can be trained to drive safely 95% of the time with minimal hardware appendages, there are surely enough “edge cases” that make having access to more data a big selling point. What we’re talking about here, of course, is safety, and that is one of the supposed big selling points of driverless vehicles.</p>
      <p>According to Wayve, the evolution of computer vision technology over the past few years is exactly what makes it possible to drive on roads with “camera-only perception,” according to a <a href="https://wayve.ai/blog/2018/10/8/vision-for-driving-with-deep-learning">blog post</a> it published last year. The company started working on its <a href="http://mi.eng.cam.ac.uk/projects/segnet/">SegNet</a> deep learning system out of the University of Cambridge in 2015, and to illustrate how far advanced it has gotten in terms of being able to understand semantics, geometry, depth, and motion from a single deep learning model, it showed these two side-by-side comparisons.</p>
      <figure>
        <video src="https://venturebeat.com/wp-content/uploads/2019/11/computer_vision_progression.gif?resize=999%2C390&amp;strip=all" autoplay="" loop=""/>
        <figcaption>Above: Computer vision progression: 2015 to 2018</figcaption>
      </figure>
      <p>With Wayve’s autonomous driving system, the cars’ eyes are basically a row of 2.3-megapixel RGB cameras with high-dynamic range, which allows them to “obtain good signal at night time and bright sunlight,” Kendall said.</p>
      <p>“We’re observing massive progress in computer vision, including with some of our own work, allowing us to perceive depth very accurately from cameras,” he continued. “To explain further, the issue we face as an industry isn’t perception, it is deciding how to act. Decision making is very complex, especially in an environment like London. This is where end-to-end learning from perception to action is so powerful.”</p>
      <p>Wayve, which recently upped sticks and moved its HQ to London, had previously raised $3.1 million. And with another $20 million in the bank, it said that it plans to launch a pilot fleet of autonomous Jaguar I-Pace electric SUV cars in Central London, replete with safety drivers. “We are launching with a dev fleet of 8 Jaguar I-Paces from our London Kings Cross HQ to develop our technology,” Kendall said. “As soon as we can demonstrate they are capable of the complexity on London’s roads, we’ll be commencing a commercial pilot launch.”</p>
      <p>There is also no ignoring the fact that Wayve has managed to secure some notable backers both from the VC and technology realm. And it’s a rare moment when a Silicon Valley investment firm looks to Europe to invest in such an early-stage self-driving car startup.</p>
      <p>“Wayve’s differentiated approach to autonomy builds on timely advances in the fields of reinforcement learning, simulation and computer vision,” said Eclipse Ventures partner Seth Winterroth. “Furthermore, by locating the company in the U.K., the team has access to an extraordinary talent pool and numerous complex testing environments.”</p>
    </article>
  </body>
</html>